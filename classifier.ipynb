{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Joykaus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the sms dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/sms-spam-collection-dataset/spam.csv', encoding=\"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove column 2, 3 and 4 as they have no useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMS  label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                      Ok lar... Joking wif u oni...      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "df['SMS'] = df['v2']\n",
    "df['label'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "df.drop(['v1', 'v2'], axis=1, inplace=True)\n",
    "train_data = df[:4400]\n",
    "test_data = df[4400:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "porter = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data = str(data)\n",
    "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr',data)\n",
    "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',cleaned)\n",
    "    cleaned = re.sub(r'£|\\$', 'moneysymb', cleaned)\n",
    "    cleaned = re.sub(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b','phonenumbr', cleaned)\n",
    "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
    "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
    "    return ' '.join(\n",
    "        porter.stem(term) \n",
    "        for term in cleaned.split()\n",
    "        if term not in set(stop_words)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sm label numbr mani time lose best one bcoz numbr numbr good friend care close frien numbr numbr get back home numbr numbr sorri call later lt gt min numbr numbr dun need use dial juz open da browser n numbr numbr numbrnd time tri numbr contact u numbr numbr ì_ b go esplanad fr home numbr numbr piti mood numbr numbr guy bitch act like numbr numbr rofl true name numbr numbr row x numbr column'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying preprocessing cleaning on test and train data\n",
    "preprocess_data(train_data)\n",
    "preprocess_data(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(classifiers, vectorizers, train_data, test_data):\n",
    "    max_score = 0\n",
    "    max_name = 0\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "        \n",
    "            # train\n",
    "            vectorize_text = vectorizer.fit_transform(train_data.SMS)\n",
    "            classifier.fit(vectorize_text, train_data.label)\n",
    "\n",
    "            # score\n",
    "            vectorize_text = vectorizer.transform(test_data.SMS)\n",
    "            score = classifier.score(vectorize_text, test_data.label)\n",
    "            name = classifier.__class__.__name__ + ' with ' + vectorizer.__class__.__name__ \n",
    "            print(name, score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_name = name\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')\n",
    "    print (max_name, max_score)\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of various classifiers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "        BernoulliNB(),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        CalibratedClassifierCV(),\n",
    "        DummyClassifier(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of various vectorizers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer(),\n",
    "        HashingVectorizer()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform classification and save results to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with CountVectorizer 0.9778156996587031\n",
      "BernoulliNB with TfidfVectorizer 0.9778156996587031\n",
      "BernoulliNB with HashingVectorizer 0.8728668941979523\n",
      "RandomForestClassifier with CountVectorizer 0.976962457337884\n",
      "RandomForestClassifier with TfidfVectorizer 0.9744027303754266\n",
      "RandomForestClassifier with HashingVectorizer 0.9684300341296929\n",
      "AdaBoostClassifier with CountVectorizer 0.9718430034129693\n",
      "AdaBoostClassifier with TfidfVectorizer 0.9692832764505119\n",
      "AdaBoostClassifier with HashingVectorizer 0.9735494880546075\n",
      "BaggingClassifier with CountVectorizer 0.9684300341296929\n",
      "BaggingClassifier with TfidfVectorizer 0.9650170648464164\n",
      "BaggingClassifier with HashingVectorizer 0.9658703071672355\n",
      "ExtraTreesClassifier with CountVectorizer 0.9795221843003413\n",
      "ExtraTreesClassifier with TfidfVectorizer 0.9803754266211604\n",
      "ExtraTreesClassifier with HashingVectorizer 0.9701365187713311\n",
      "GradientBoostingClassifier with CountVectorizer 0.9684300341296929\n",
      "GradientBoostingClassifier with TfidfVectorizer 0.9667235494880546\n",
      "GradientBoostingClassifier with HashingVectorizer 0.9726962457337884\n",
      "DecisionTreeClassifier with CountVectorizer 0.9650170648464164\n",
      "DecisionTreeClassifier with TfidfVectorizer 0.962457337883959\n",
      "DecisionTreeClassifier with HashingVectorizer 0.962457337883959\n",
      "CalibratedClassifierCV with CountVectorizer 0.9863481228668942\n",
      "CalibratedClassifierCV with TfidfVectorizer 0.9863481228668942\n",
      "CalibratedClassifierCV with HashingVectorizer 0.9820819112627986\n",
      "DummyClassifier with CountVectorizer 0.7866894197952219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joykaus\\anaconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n",
      "C:\\Users\\Joykaus\\anaconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier with TfidfVectorizer 0.7636518771331058\n",
      "DummyClassifier with HashingVectorizer 0.7807167235494881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joykaus\\anaconda3\\lib\\site-packages\\sklearn\\dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassiveAggressiveClassifier with CountVectorizer 0.9829351535836177\n",
      "PassiveAggressiveClassifier with TfidfVectorizer 0.985494880546075\n",
      "PassiveAggressiveClassifier with HashingVectorizer 0.9829351535836177\n",
      "RidgeClassifier with CountVectorizer 0.9812286689419796\n",
      "RidgeClassifier with TfidfVectorizer 0.9829351535836177\n",
      "RidgeClassifier with HashingVectorizer 0.9820819112627986\n",
      "RidgeClassifierCV with CountVectorizer 0.9829351535836177\n",
      "RidgeClassifierCV with TfidfVectorizer 0.984641638225256\n",
      "RidgeClassifierCV with HashingVectorizer 0.9803754266211604\n",
      "SGDClassifier with CountVectorizer 0.9829351535836177\n",
      "SGDClassifier with TfidfVectorizer 0.985494880546075\n",
      "SGDClassifier with HashingVectorizer 0.9829351535836177\n",
      "OneVsRestClassifier with CountVectorizer 0.9863481228668942\n",
      "OneVsRestClassifier with TfidfVectorizer 0.9880546075085325\n",
      "OneVsRestClassifier with HashingVectorizer 0.9829351535836177\n",
      "OneVsRestClassifier with CountVectorizer 0.9837883959044369\n",
      "OneVsRestClassifier with TfidfVectorizer 0.9752559726962458\n",
      "OneVsRestClassifier with HashingVectorizer 0.9684300341296929\n",
      "KNeighborsClassifier with CountVectorizer 0.924061433447099\n",
      "KNeighborsClassifier with TfidfVectorizer 0.962457337883959\n",
      "KNeighborsClassifier with HashingVectorizer 0.9607508532423208\n",
      "===========================================\n",
      "===========================================\n",
      "PassiveAggressiveClassifier with HashingVectorizer 0.9829351535836177\n",
      "===========================================\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "perform(\n",
    "    classifiers,\n",
    "    vectorizers,\n",
    "    train_data,\n",
    "    test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Selecting the best combination to create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='linear', max_iter=-1,\n",
       "                                  probability=True, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier with best accuracy\n",
    "Classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "Vectorizer = TfidfVectorizer()\n",
    "vectorize_text = Vectorizer.fit_transform(train_data.SMS)\n",
    "Classifier.fit(vectorize_text, train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS= 'You have an interview tomorrow'\n",
    "vectorize_message = Vectorizer.transform([SMS])\n",
    "predict = Classifier.predict(vectorize_message)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "if predict == 0:\n",
    "    print ('not spam')\n",
    "else:\n",
    "    print ('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS = ' won a 1 week FREE membership in our $100,000 Prize Jackpot! Txt the word: C'\n",
    "vectorize_message = Vectorizer.transform([SMS])\n",
    "predict = Classifier.predict(vectorize_message)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "if predict == 0:\n",
    "    print ('not spam')\n",
    "else:\n",
    "    print ('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
